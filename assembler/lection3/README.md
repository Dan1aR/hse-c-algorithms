# Лекция 2025-02-11
Гугл диск: https://drive.google.com/drive/folders/13scXEL-Xlgm1f4SbowCtEXlRd6-8DXj7?dmr=1&ec=wgc-drive-globalnav-goto

Разбираем cache.cpp - как вообще понять че у нас там с кешами?
- при хардварной оптимизации это самый основной ресурс
- ядро всегда пишет и читает в L1
- кэш всегда читается линиями (в зависимости от архи 32/64/128 байт)

Кэш бывает:
- Не ассоциативный - когда каждому адресу (физическому из памяти) известно в какую линию он попадет (например они связаны через какое-то правило типо остаток от деления)
- Ассоциативная часть - когда лежит маленька хэш-таблица которая хранит инфу о том, какой адрес где лежит

Как будем проверять что мы не пиздим:
- Берем вектор случайных чисел и прыгаем по нему рандомно (см. программу)
- И там получилось короче, что действительно когда мы из L1-L2 переходим в L3 просадка, а когда из L3 в RAM - вообще пиздец


## Теперь семинар - как нам понять что у нас тормозит!
Смотрим `perf`; Например у меня есть какой-то запущенный: ./a.out с PID 123  
`perf stat -p 123 sleep 15`  
Он соберет счетчики которые говорят о производительноси  
`perf stat -B -e cache-references.cache-misses -p 123 sleep 15`  
И тут будет % сколько мы мисаем в кеш и ходим в RAM  
Вообще есть команда где он собирает сразу кучу счетчиков  

Можно не через PID, а сразу вместо `-p PID sleep 15 ` передать `./a.out`: но это плохо потому что это буквально замер на холодную; Надо выделять куски, зацикливать их в бесконечность и делать через PID
А есть ещё команда `perf report`, она собирает статистику на каких командах у нас программа сидит больше всего

То есть всегда два шага: сначала смотрим `perf stat` смотрим что со счетчиками, и ещё обязательно смотрим в `perf report` и ещё строим flame graph чтобы мы могли визуально понимать, где тратится время;
